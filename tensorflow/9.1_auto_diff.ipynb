{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients using AutoDiff\n",
    "\n",
    "This section is to understand how to compute gradients automatically using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.000003007075065, 10.000000003174137)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2\n",
    "\n",
    "# of course we can find the derivative at specific points by approximating using a small delta\n",
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps, (f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using tensorflow autodiff\n",
    "\n",
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient is automatically ereased when gradient is called\n",
    "##--> tape.gradient(z, w1)\n",
    "\n",
    "# another way is to set persistent=True so the gradient is over ereased, but \n",
    "# need to remember to delete the tape\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "g1 = tape.gradient(z, [w1])\n",
    "g2 = tape.gradient(z, [w2])\n",
    "\n",
    "g1, g2\n",
    "\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Normally only tracks variables. but can also be set to track constant.\n",
    "## this can be useful for some case. for example, implement a regularisation loss that \n",
    "## panelises activations that very a lot when inputs vary little\n",
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "    \n",
    "gradients = tape.gradient(z, [c1, c2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# test_size is default to 0.25\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_valid = StandardScaler().fit_transform(X_valid)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "363/363 [==============================] - 0s 802us/step - loss: 2.3630 - mse: 2.3630 - val_loss: 0.8399 - val_mse: 0.8399\n",
      "Epoch 2/40\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.7489 - mse: 0.7489 - val_loss: 0.5844 - val_mse: 0.5844\n",
      "Epoch 3/40\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.5571 - mse: 0.5571 - val_loss: 0.5690 - val_mse: 0.5690\n",
      "Epoch 4/40\n",
      "363/363 [==============================] - 0s 612us/step - loss: 0.4744 - mse: 0.4744 - val_loss: 0.5726 - val_mse: 0.5726\n",
      "Epoch 5/40\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.4419 - mse: 0.4419 - val_loss: 0.5572 - val_mse: 0.5572\n",
      "Epoch 6/40\n",
      "363/363 [==============================] - 0s 620us/step - loss: 0.4246 - mse: 0.4246 - val_loss: 0.5781 - val_mse: 0.5781\n",
      "Epoch 7/40\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.4112 - mse: 0.4112 - val_loss: 0.5455 - val_mse: 0.5455\n",
      "Epoch 8/40\n",
      "363/363 [==============================] - 0s 609us/step - loss: 0.4051 - mse: 0.4051 - val_loss: 0.5627 - val_mse: 0.5627\n",
      "Epoch 9/40\n",
      "363/363 [==============================] - 0s 579us/step - loss: 0.3998 - mse: 0.3998 - val_loss: 0.5494 - val_mse: 0.5494\n",
      "Epoch 10/40\n",
      "363/363 [==============================] - 0s 612us/step - loss: 0.3927 - mse: 0.3927 - val_loss: 0.5956 - val_mse: 0.5956\n",
      "Epoch 11/40\n",
      "363/363 [==============================] - 0s 617us/step - loss: 0.3877 - mse: 0.3877 - val_loss: 0.5522 - val_mse: 0.5522\n",
      "Epoch 12/40\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3857 - mse: 0.3857 - val_loss: 0.5574 - val_mse: 0.5574\n",
      "Epoch 13/40\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.5770 - val_mse: 0.5770\n",
      "Epoch 14/40\n",
      "363/363 [==============================] - 0s 614us/step - loss: 0.3769 - mse: 0.3769 - val_loss: 0.5770 - val_mse: 0.5770\n",
      "Epoch 15/40\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.3733 - mse: 0.3733 - val_loss: 0.5949 - val_mse: 0.5949\n",
      "Epoch 16/40\n",
      "363/363 [==============================] - 0s 607us/step - loss: 0.3697 - mse: 0.3697 - val_loss: 0.6018 - val_mse: 0.6018\n",
      "Epoch 17/40\n",
      "363/363 [==============================] - 0s 617us/step - loss: 0.3695 - mse: 0.3695 - val_loss: 0.5850 - val_mse: 0.5850\n",
      "Epoch 18/40\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.3684 - mse: 0.3684 - val_loss: 0.5944 - val_mse: 0.5944\n",
      "Epoch 19/40\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.3691 - mse: 0.3691 - val_loss: 0.6058 - val_mse: 0.6058\n",
      "Epoch 20/40\n",
      "363/363 [==============================] - 0s 598us/step - loss: 0.3614 - mse: 0.3614 - val_loss: 0.5774 - val_mse: 0.5774\n",
      "Epoch 21/40\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.3642 - mse: 0.3642 - val_loss: 0.5936 - val_mse: 0.5936\n",
      "Epoch 22/40\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.3624 - mse: 0.3624 - val_loss: 0.5777 - val_mse: 0.5777\n",
      "Epoch 23/40\n",
      "363/363 [==============================] - 0s 645us/step - loss: 0.3589 - mse: 0.3589 - val_loss: 0.6103 - val_mse: 0.6103\n",
      "Epoch 24/40\n",
      "363/363 [==============================] - 0s 598us/step - loss: 0.3551 - mse: 0.3551 - val_loss: 0.5965 - val_mse: 0.5965\n",
      "Epoch 25/40\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.3573 - mse: 0.3573 - val_loss: 0.6218 - val_mse: 0.6218\n",
      "Epoch 26/40\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.3534 - mse: 0.3534 - val_loss: 0.6245 - val_mse: 0.6245\n",
      "Epoch 27/40\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.3485 - mse: 0.3485 - val_loss: 0.6638 - val_mse: 0.6638\n",
      "Epoch 28/40\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.3481 - mse: 0.3481 - val_loss: 0.6345 - val_mse: 0.6345\n",
      "Epoch 29/40\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.3470 - mse: 0.3470 - val_loss: 0.6549 - val_mse: 0.6549\n",
      "Epoch 30/40\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.3455 - mse: 0.3455 - val_loss: 0.6722 - val_mse: 0.6722\n",
      "Epoch 31/40\n",
      "363/363 [==============================] - 0s 612us/step - loss: 0.3469 - mse: 0.3469 - val_loss: 0.6563 - val_mse: 0.6563\n",
      "Epoch 32/40\n",
      "363/363 [==============================] - 0s 573us/step - loss: 0.3459 - mse: 0.3459 - val_loss: 0.6951 - val_mse: 0.6951\n",
      "Epoch 33/40\n",
      "363/363 [==============================] - 0s 607us/step - loss: 0.3502 - mse: 0.3502 - val_loss: 0.6538 - val_mse: 0.6538\n",
      "Epoch 34/40\n",
      "363/363 [==============================] - 0s 598us/step - loss: 0.3445 - mse: 0.3445 - val_loss: 0.7140 - val_mse: 0.7140\n",
      "Epoch 35/40\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.3410 - mse: 0.3410 - val_loss: 0.6793 - val_mse: 0.6793\n",
      "Epoch 36/40\n",
      "363/363 [==============================] - 0s 601us/step - loss: 0.3403 - mse: 0.3403 - val_loss: 0.7360 - val_mse: 0.7360\n",
      "Epoch 37/40\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.3394 - mse: 0.3394 - val_loss: 0.6851 - val_mse: 0.6851\n",
      "Epoch 38/40\n",
      "363/363 [==============================] - 0s 612us/step - loss: 0.3367 - mse: 0.3367 - val_loss: 0.7083 - val_mse: 0.7083\n",
      "Epoch 39/40\n",
      "363/363 [==============================] - 0s 593us/step - loss: 0.3356 - mse: 0.3356 - val_loss: 0.6437 - val_mse: 0.6437\n",
      "Epoch 40/40\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.3383 - mse: 0.3383 - val_loss: 0.7112 - val_mse: 0.7112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b61cfae340>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "l2_reg = keras.regularizers.l2(1.0)\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    Dense(16, input_shape = X_train.shape[1:] , activation = 'relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "# how we would compile and run the model\n",
    "model.compile(optimizer=\"adam\", loss = 'mse', metrics=['mse'])\n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def random_batch(X, y, batch_size = 30):\n",
    "    idx = np.random.randint(len(X), size = batch_size)\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "def print_status_bar(iteration, total, loss, metrics = None):\n",
    "    metrics = \"-\".join([f\"{m.name}: {m.result()}\"\n",
    "                        for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end = end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Adam(lr = 0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "tf.Tensor(1.7556337, shape=(), dtype=float32) tf.Tensor(1.7556337, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2 loops, top is for epochs, and second is for steps (see above)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch: {epoch}/{n_epochs}\")\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)               # grab a random batch\n",
    "        with tf.GradientTape() as tape:                                 # gradient tape created for loss\n",
    "            y_pred = model(X_batch, training = True)                    # calculate prediction\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))        # calculate loss for the batch\n",
    "            loss = tf.add_n([main_loss] + model.losses)                 # add other losses (for regularisation for example)\n",
    "            print(main_loss, loss)\n",
    "            break\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)      # get gradients of all trainable variables\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # apply gradients, smart, as this can be optimiser specific such as learning rate, momentum, etc\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "    break\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in tensorflow/9.1_auto_diff.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 964b691] initial commit\n",
      " 1 file changed, 436 insertions(+)\n",
      " create mode 100644 tensorflow/9.1_auto_diff.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/auslei/python.git\n",
      "   61e93b1..964b691  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git add 9.1_auto_diff.ipynb\n",
    "!git commit -m \"initial commit\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\python_kernels\\ml_with_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python_kernels\\ml_with_tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36madd_n\u001b[1;34m(inputs, name)\u001b[0m\n\u001b[0;32m   3495\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections_abc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3496\u001b[1;33m     raise ValueError(\"inputs must be an iterable of at least one \"\n\u001b[0m\u001b[0;32m   3497\u001b[0m                      \"Tensor/IndexedSlices with the same dtype and shape\")\n",
      "\u001b[1;31mValueError\u001b[0m: inputs must be an iterable of at least one Tensor/IndexedSlices with the same dtype and shape",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-98337c6e29df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\python_kernels\\ml_with_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m       \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python_kernels\\ml_with_tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(op, args, kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m   \"\"\"\n\u001b[0;32m    117\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mdispatcher\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDISPATCH_ATTR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python_kernels\\ml_with_tf\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_dispatch.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arg_is_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m       \u001b[0mfound_ragged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ragged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m           \u001b[0mfound_ragged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    tf.add_n(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_with_tf",
   "language": "python",
   "name": "ml_with_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
